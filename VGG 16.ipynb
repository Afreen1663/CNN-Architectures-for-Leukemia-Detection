{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7d1545a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 5.639426,
     "end_time": "2024-01-17T14:00:27.343662",
     "exception": false,
     "start_time": "2024-01-17T14:00:21.704236",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "#VGG \n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9afe556f",
   "metadata": {
    "papermill": {
     "duration": 13.144824,
     "end_time": "2024-01-17T14:00:40.504621",
     "exception": false,
     "start_time": "2024-01-17T14:00:27.359797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing lib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14236ad0",
   "metadata": {
    "papermill": {
     "duration": 0.02302,
     "end_time": "2024-01-17T14:00:40.540835",
     "exception": false,
     "start_time": "2024-01-17T14:00:40.517815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def define_paths(dir):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    folds = os.listdir(dir)\n",
    "    for fold in folds:\n",
    "        foldpath = os.path.join(dir, fold)\n",
    "        filelist = os.listdir(foldpath)\n",
    "        for file in filelist:\n",
    "            fpath = os.path.join(foldpath, file)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(fold)\n",
    "    return filepaths, labels\n",
    "\n",
    "\n",
    "def define_df(files, classes):\n",
    "    Fseries = pd.Series(files, name= 'filepaths')\n",
    "    Lseries = pd.Series(classes, name='labels')\n",
    "    return pd.concat([Fseries, Lseries], axis= 1)\n",
    "\n",
    "\n",
    "def create_df(dir):\n",
    "    files, classes = define_paths(dir)\n",
    "    df = define_df(files, classes)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75dc3869",
   "metadata": {
    "papermill": {
     "duration": 3.639549,
     "end_time": "2024-01-17T14:00:44.193119",
     "exception": false,
     "start_time": "2024-01-17T14:00:40.553570",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 validated image filenames belonging to 10 classes.\n",
      "Found 200 validated image filenames belonging to 10 classes.\n",
      "Found 200 validated image filenames belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "#training/test\n",
    "def create_gens(train_df, valid_df, test_df, batch_size):\n",
    "    img_size = (224, 224)\n",
    "    channels = 3\n",
    "    img_shape = (img_size[0], img_size[1], channels)\n",
    "    ts_length = len(test_df)\n",
    "    def scalar(img):\n",
    "        return img\n",
    "    tr_gen = ImageDataGenerator(preprocessing_function= scalar, horizontal_flip= True)\n",
    "    ts_gen = ImageDataGenerator(preprocessing_function= scalar)\n",
    "    train_gen = tr_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= 40)\n",
    "    valid_gen = ts_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= True, batch_size= 40)\n",
    "    test_gen = ts_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n",
    "                                        color_mode= 'rgb', shuffle= False, batch_size= 40)\n",
    "    return train_gen, valid_gen, test_gen\n",
    "\n",
    "\n",
    "dir = 'DATASET/TRAIN'\n",
    "\n",
    "df = create_df(dir)\n",
    "train_df, test_valid_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "test_df, valid_df = train_test_split(test_valid_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Get Generators\n",
    "batch_size = 32\n",
    "train_gen, valid_gen, test_gen = create_gens(train_df, valid_df, test_df, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e711f1fe",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.030318,
     "end_time": "2024-01-17T14:00:44.237026",
     "exception": false,
     "start_time": "2024-01-17T14:00:44.206708",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>968</th>\n",
       "      <td>DATASET/TRAIN\\EOS\\EOS_05180.jpg</td>\n",
       "      <td>EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>DATASET/TRAIN\\BAS\\BAS_00061.jpg</td>\n",
       "      <td>BAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>DATASET/TRAIN\\EOS\\EOS_05021.jpg</td>\n",
       "      <td>EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>692</th>\n",
       "      <td>DATASET/TRAIN\\EBO\\EBO_26109.jpg</td>\n",
       "      <td>EBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>DATASET/TRAIN\\BLA\\BLA_11025.jpg</td>\n",
       "      <td>BLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>DATASET/TRAIN\\HAC\\HAC_00140.jpg</td>\n",
       "      <td>HAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>DATASET/TRAIN\\LYT\\LYT_19111.jpg</td>\n",
       "      <td>LYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>DATASET/TRAIN\\EOS\\EOS_05065.jpg</td>\n",
       "      <td>EOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>DATASET/TRAIN\\MMZ\\MMZ_02071.jpg</td>\n",
       "      <td>MMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1126</th>\n",
       "      <td>DATASET/TRAIN\\HAC\\HAC_00136.jpg</td>\n",
       "      <td>HAC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths labels\n",
       "968   DATASET/TRAIN\\EOS\\EOS_05180.jpg    EOS\n",
       "240   DATASET/TRAIN\\BAS\\BAS_00061.jpg    BAS\n",
       "819   DATASET/TRAIN\\EOS\\EOS_05021.jpg    EOS\n",
       "692   DATASET/TRAIN\\EBO\\EBO_26109.jpg    EBO\n",
       "420   DATASET/TRAIN\\BLA\\BLA_11025.jpg    BLA\n",
       "...                               ...    ...\n",
       "1130  DATASET/TRAIN\\HAC\\HAC_00140.jpg    HAC\n",
       "1294  DATASET/TRAIN\\LYT\\LYT_19111.jpg    LYT\n",
       "860   DATASET/TRAIN\\EOS\\EOS_05065.jpg    EOS\n",
       "1459  DATASET/TRAIN\\MMZ\\MMZ_02071.jpg    MMZ\n",
       "1126  DATASET/TRAIN\\HAC\\HAC_00136.jpg    HAC\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82c3f639",
   "metadata": {
    "_kg_hide-input": false,
    "_kg_hide-output": true,
    "papermill": {
     "duration": 0.027198,
     "end_time": "2024-01-17T14:00:44.278234",
     "exception": false,
     "start_time": "2024-01-17T14:00:44.251036",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filepaths</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1198</th>\n",
       "      <td>DATASET/TRAIN\\HAC\\HAC_00214.jpg</td>\n",
       "      <td>HAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>DATASET/TRAIN\\EBO\\EBO_26141.jpg</td>\n",
       "      <td>EBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1381</th>\n",
       "      <td>DATASET/TRAIN\\LYT\\LYT_19220.jpg</td>\n",
       "      <td>LYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>DATASET/TRAIN\\ART\\ART_19079.jpg</td>\n",
       "      <td>ART</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>DATASET/TRAIN\\EBO\\EBO_26034.jpg</td>\n",
       "      <td>EBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>DATASET/TRAIN\\BAS\\BAS_00252.jpg</td>\n",
       "      <td>BAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>DATASET/TRAIN\\EBO\\EBO_26023.jpg</td>\n",
       "      <td>EBO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>DATASET/TRAIN\\LYT\\LYT_19198.jpg</td>\n",
       "      <td>LYT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1510</th>\n",
       "      <td>DATASET/TRAIN\\MMZ\\MMZ_02128.jpg</td>\n",
       "      <td>MMZ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>DATASET/TRAIN\\BLA\\BLA_11037.jpg</td>\n",
       "      <td>BLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            filepaths labels\n",
       "1198  DATASET/TRAIN\\HAC\\HAC_00214.jpg    HAC\n",
       "720   DATASET/TRAIN\\EBO\\EBO_26141.jpg    EBO\n",
       "1381  DATASET/TRAIN\\LYT\\LYT_19220.jpg    LYT\n",
       "63    DATASET/TRAIN\\ART\\ART_19079.jpg    ART\n",
       "630   DATASET/TRAIN\\EBO\\EBO_26034.jpg    EBO\n",
       "...                               ...    ...\n",
       "383   DATASET/TRAIN\\BAS\\BAS_00252.jpg    BAS\n",
       "620   DATASET/TRAIN\\EBO\\EBO_26023.jpg    EBO\n",
       "1364  DATASET/TRAIN\\LYT\\LYT_19198.jpg    LYT\n",
       "1510  DATASET/TRAIN\\MMZ\\MMZ_02128.jpg    MMZ\n",
       "429   DATASET/TRAIN\\BLA\\BLA_11037.jpg    BLA\n",
       "\n",
       "[200 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81e22280",
   "metadata": {
    "papermill": {
     "duration": 0.022607,
     "end_time": "2024-01-17T14:00:44.316094",
     "exception": false,
     "start_time": "2024-01-17T14:00:44.293487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30114939",
   "metadata": {
    "papermill": {
     "duration": 0.022754,
     "end_time": "2024-01-17T14:00:44.353365",
     "exception": false,
     "start_time": "2024-01-17T14:00:44.330611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ff494d7",
   "metadata": {
    "papermill": {
     "duration": 0.022551,
     "end_time": "2024-01-17T14:00:44.389961",
     "exception": false,
     "start_time": "2024-01-17T14:00:44.367410",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dd4e863",
   "metadata": {
    "_kg_hide-output": true,
    "papermill": {
     "duration": 276.838598,
     "end_time": "2024-01-17T14:13:29.550871",
     "exception": false,
     "start_time": "2024-01-17T14:08:52.712273",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58889256/58889256 [==============================] - 5s 0us/step\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:From C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "40/40 [==============================] - ETA: 0s - loss: 2.4337 - accuracy: 0.1806  \n",
      "Epoch 1: val_accuracy improved from -inf to 0.17500, saving model to best_model_vgg.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afree\\anaconda3\\envs\\env\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 279s 7s/step - loss: 2.4337 - accuracy: 0.1806 - val_loss: 2.3171 - val_accuracy: 0.1750\n",
      "Epoch 2/5\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.9477 - accuracy: 0.3281  \n",
      "Epoch 2: val_accuracy improved from 0.17500 to 0.29000, saving model to best_model_vgg.h5\n",
      "40/40 [==============================] - 230s 6s/step - loss: 1.9477 - accuracy: 0.3281 - val_loss: 1.9205 - val_accuracy: 0.2900\n",
      "Epoch 3/5\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.7189 - accuracy: 0.4050  \n",
      "Epoch 3: val_accuracy improved from 0.29000 to 0.34500, saving model to best_model_vgg.h5\n",
      "40/40 [==============================] - 226s 6s/step - loss: 1.7189 - accuracy: 0.4050 - val_loss: 1.8000 - val_accuracy: 0.3450\n",
      "Epoch 4/5\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.5061 - accuracy: 0.4906  \n",
      "Epoch 4: val_accuracy improved from 0.34500 to 0.40000, saving model to best_model_vgg.h5\n",
      "40/40 [==============================] - 240s 6s/step - loss: 1.5061 - accuracy: 0.4906 - val_loss: 1.7001 - val_accuracy: 0.4000\n",
      "Epoch 5/5\n",
      "40/40 [==============================] - ETA: 0s - loss: 1.3641 - accuracy: 0.5450  \n",
      "Epoch 5: val_accuracy improved from 0.40000 to 0.40500, saving model to best_model_vgg.h5\n",
      "40/40 [==============================] - 255s 6s/step - loss: 1.3641 - accuracy: 0.5450 - val_loss: 1.6203 - val_accuracy: 0.4050\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Assuming train_gen and valid_gen are your image data generators\n",
    "\n",
    "img_size = (224, 224)\n",
    "channels = 3\n",
    "img_shape = (img_size[0], img_size[1], channels)\n",
    "class_count = len(list(train_gen.class_indices.keys()))\n",
    "\n",
    "# Create pre-trained model\n",
    "base_model = tf.keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=img_shape, pooling='max')\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    BatchNormalization(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "     Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(class_count, activation='softmax')\n",
    "])\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define filepath to save the best model\n",
    "filepath = 'best_model_vgg.h5'\n",
    "\n",
    "# Create ModelCheckpoint callback to save the best model based on validation accuracy\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "# Train the model with the added callback\n",
    "history = model.fit(\n",
    "    x=train_gen,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=valid_gen,\n",
    "    callbacks=[checkpoint]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb43c6da",
   "metadata": {
    "papermill": {
     "duration": 29.453854,
     "end_time": "2024-01-17T14:13:59.374037",
     "exception": false,
     "start_time": "2024-01-17T14:13:29.920183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 22s 5s/step - loss: 0.7819 - accuracy: 0.8125\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.5621 - accuracy: 0.4187\n",
      "4/4 [==============================] - 20s 5s/step - loss: 1.5239 - accuracy: 0.5125\n",
      "Train Loss:  0.7819350361824036\n",
      "Train Accuracy:  0.8125\n",
      "--------------------\n",
      "Validation Loss:  1.562109112739563\n",
      "Validation Accuracy:  0.41874998807907104\n",
      "--------------------\n",
      "Test Loss:  1.5239102840423584\n",
      "Test Accuracy:  0.512499988079071\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input, Average\n",
    "\n",
    "\n",
    "\n",
    "model= load_model('best_model_vgg.h5')\n",
    "\n",
    "ts_length = len(test_df)\n",
    "test_batch_size = test_batch_size = max(sorted([ts_length // n for n in range(1, ts_length + 1) if ts_length%n == 0 and ts_length/n <= 80]))\n",
    "test_steps = ts_length // test_batch_size\n",
    "train_score = model.evaluate(train_gen, steps= test_steps, verbose= 1)\n",
    "valid_score = model.evaluate(valid_gen, steps= test_steps, verbose= 1)\n",
    "test_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n",
    "\n",
    "print(\"Train Loss: \", train_score[0])\n",
    "print(\"Train Accuracy: \", train_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Validation Loss: \", valid_score[0])\n",
    "print(\"Validation Accuracy: \", valid_score[1])\n",
    "print('-' * 20)\n",
    "print(\"Test Loss: \", test_score[0])\n",
    "print(\"Test Accuracy: \", test_score[1])"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1544742,
     "sourceId": 2546969,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 830.996806,
   "end_time": "2024-01-17T14:14:09.188939",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-17T14:00:18.192133",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
